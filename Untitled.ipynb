{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e9faf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split, cross_val_predict, cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fccff48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ VERI ------------\n",
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "LABEL: rec.autos = 7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "data = fetch_20newsgroups()\n",
    "\n",
    "print(\"------------ VERI ------------\")\n",
    "print(data.data[0].strip())\n",
    "print(\"\\nLABEL:\", data.target_names[data.target[0]],\n",
    "      \"=\", data.target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf0c1d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>On a slightly different note:\\n\\nThere are two...</td>\n",
       "      <td>6</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gordon Banks quoted and added...\\n\\ngb&gt; In art...</td>\n",
       "      <td>6</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\\n\\nOops! Quite right. I got so busy that I sa...</td>\n",
       "      <td>6</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\\n\\n...in other words faith in a .357 is far ...</td>\n",
       "      <td>6</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\\nLet's see, if Alexander destroyed Tyre, and ...</td>\n",
       "      <td>6</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text target  \\\n",
       "0   On a slightly different note:\\n\\nThere are two...      6   \n",
       "2   Gordon Banks quoted and added...\\n\\ngb> In art...      6   \n",
       "13  \\n\\nOops! Quite right. I got so busy that I sa...      6   \n",
       "17   \\n\\n...in other words faith in a .357 is far ...      6   \n",
       "18  \\nLet's see, if Alexander destroyed Tyre, and ...      6   \n",
       "\n",
       "                 topic  \n",
       "0   talk.religion.misc  \n",
       "2   talk.religion.misc  \n",
       "13  talk.religion.misc  \n",
       "17  talk.religion.misc  \n",
       "18  talk.religion.misc  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = ['talk.religion.misc', 'comp.graphics', 'sci.space', 'talk.politics.guns', 'rec.sport.hockey',\n",
    "             'rec.autos', 'sci.crypt']\n",
    "\n",
    "newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'), categories=categories)\n",
    "\n",
    "df_ = pd.DataFrame([newsgroups.data, newsgroups.target.tolist()]).T\n",
    "df_.columns = ['text', 'target']\n",
    "targets = pd.DataFrame(newsgroups.target_names)\n",
    "targets.columns=['topic']\n",
    "df = pd.merge(df_, targets, left_on='target', right_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfe431c",
   "metadata": {},
   "source": [
    "Metnin Ön İşleme ve Sayısallaştırma Süreci\n",
    "\n",
    "Lower-case\n",
    "Noktalama işaretleri, özel karakterlerin ve sayıların silinmesi\n",
    "Tokenize işlemi\n",
    "Stop-words’lerin silinmesi\n",
    "Stemming / Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "622497c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\Ensar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\Ensar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\Ensar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\Ensar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\Ensar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\Ensar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\Ensar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\Ensar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\Ensar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\Ensar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\Ensar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\Ensar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\Ensar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\Ensar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\Ensar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\Ensar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\Ensar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\Ensar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\Ensar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\Ensar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\Ensar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\Ensar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import nltk\n",
    "stemmer = SnowballStemmer('english')\n",
    "import nltk; nltk.download('popular')\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07331376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>topic</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>On a slightly different note:\\n\\nThere are two...</td>\n",
       "      <td>6</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>slight differ note build state number roof man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gordon Banks quoted and added...\\n\\ngb&gt; In art...</td>\n",
       "      <td>6</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>gordon bank quot add articl acsu buffalo chris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\\n\\nOops! Quite right. I got so busy that I sa...</td>\n",
       "      <td>6</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>oop right busi save frank post intend respond ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\\n\\n...in other words faith in a .357 is far ...</td>\n",
       "      <td>6</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>word faith stronger faith provid miracl follow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\\nLet's see, if Alexander destroyed Tyre, and ...</td>\n",
       "      <td>6</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>alexand destroy tyre peopl construct hous peop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6438</th>\n",
       "      <td>\\n\\nI'd go for a '39 Lincoln Continental if I ...</td>\n",
       "      <td>1</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>lincoln continent edsel ford design look abort...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6441</th>\n",
       "      <td>\\nThe answer to your question is...sort of. Vo...</td>\n",
       "      <td>1</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>answer question sort volkswagen robust version...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6445</th>\n",
       "      <td>\\nOh come on, Silly, all you have to do is cut...</td>\n",
       "      <td>1</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>come silli hole hood tube hole think intak thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6465</th>\n",
       "      <td>Could someone explain how to make sense of dra...</td>\n",
       "      <td>1</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>explain sens drag coeffici mention magazin und...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6472</th>\n",
       "      <td>\\n\\n\\n\\n\\n\\nOh, well... I have to admit that t...</td>\n",
       "      <td>1</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>admit disgust featur volvo market look like vo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6478 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text target  \\\n",
       "0     On a slightly different note:\\n\\nThere are two...      6   \n",
       "2     Gordon Banks quoted and added...\\n\\ngb> In art...      6   \n",
       "13    \\n\\nOops! Quite right. I got so busy that I sa...      6   \n",
       "17     \\n\\n...in other words faith in a .357 is far ...      6   \n",
       "18    \\nLet's see, if Alexander destroyed Tyre, and ...      6   \n",
       "...                                                 ...    ...   \n",
       "6438  \\n\\nI'd go for a '39 Lincoln Continental if I ...      1   \n",
       "6441  \\nThe answer to your question is...sort of. Vo...      1   \n",
       "6445  \\nOh come on, Silly, all you have to do is cut...      1   \n",
       "6465  Could someone explain how to make sense of dra...      1   \n",
       "6472  \\n\\n\\n\\n\\n\\nOh, well... I have to admit that t...      1   \n",
       "\n",
       "                   topic                                       cleaned_text  \n",
       "0     talk.religion.misc  slight differ note build state number roof man...  \n",
       "2     talk.religion.misc  gordon bank quot add articl acsu buffalo chris...  \n",
       "13    talk.religion.misc  oop right busi save frank post intend respond ...  \n",
       "17    talk.religion.misc  word faith stronger faith provid miracl follow...  \n",
       "18    talk.religion.misc  alexand destroy tyre peopl construct hous peop...  \n",
       "...                  ...                                                ...  \n",
       "6438           rec.autos  lincoln continent edsel ford design look abort...  \n",
       "6441           rec.autos  answer question sort volkswagen robust version...  \n",
       "6445           rec.autos  come silli hole hood tube hole think intak thi...  \n",
       "6465           rec.autos  explain sens drag coeffici mention magazin und...  \n",
       "6472           rec.autos  admit disgust featur volvo market look like vo...  \n",
       "\n",
       "[6478 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Noktalama işaretleri, özel karakterlerin ve sayıların silinmesi\n",
    "\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return \" \".join(result)\n",
    "\n",
    "processed_docs = df['text'].map(preprocess)\n",
    "df['cleaned_text'] = processed_docs\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b8384fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TF-IDF yaklaşımında hem ilgili terimin haber içerisindeki sıklığına \n",
    "(Term Frequency – TF) \n",
    "hem de bütün haberler içerisindeki önemine bakılır (Inverse Document Frequency – IDF).\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vector = TfidfVectorizer(min_df = 0., max_df = 1., use_idf = True)\n",
    "tfidf_matris = tfidf_vector.fit_transform(df.cleaned_text)\n",
    "tfidf_matris = tfidf_matris.toarray()\n",
    "\n",
    "# tfidf vector içerisindeki tüm özellikleri al\n",
    "terimler = tfidf_vector.get_feature_names_out()\n",
    "\n",
    "# dokuman - terim matrisini göster\n",
    "tfidf_df = pd.DataFrame(np.round(tfidf_matris, 3), columns=terimler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6817fd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelin Oluşturulması\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "input_dim = df.shape[1]  # Öznitelik Sayısı\n",
    "\n",
    "num_classes = 7 # Sınıf sayısı\n",
    "\n",
    "# Model oluşturuluyor\n",
    "model = Sequential() \n",
    "\n",
    "# Modele üç gizli katman ekliyoruz. Katmandaların üçünde de 64 düğüm var ve her birinde \"relu\" aktivasyon fonksiyonunu kullanılıyor. \n",
    "model.add(Dense(64, input_dim=input_dim, activation='relu')) \n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Modelimizin ezberlemesini önlemek için Dropout katmanını kullanıyoruz. \n",
    "# Dropout katmanı her adımda belirtilen orandaki girdiyi rassal olarak sıfıra eşitleyerek modelin veriye aşırı uyum sağlamasının önüne geçer.\n",
    "# Dropout değeri 0 ile 1 arasındadır.\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "# Son eklediğimiz katman ise çıktı katmanıdır. Çoklu sınıflandırma problemi üzerine çalıştığımız için \"softmax\" aktivasyon fonksiyonunu kullanıyoruz. \n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92f9a4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                320       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 7)                 455       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9095 (35.53 KB)\n",
      "Trainable params: 9095 (35.53 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='rmsprop', \n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90b4ab96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>slight differ note build state number roof man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>gordon bank quot add articl acsu buffalo chris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>oop right busi save frank post intend respond ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>word faith stronger faith provid miracl follow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>alexand destroy tyre peopl construct hous peop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6438</th>\n",
       "      <td>rec.autos</td>\n",
       "      <td>lincoln continent edsel ford design look abort...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6441</th>\n",
       "      <td>rec.autos</td>\n",
       "      <td>answer question sort volkswagen robust version...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6445</th>\n",
       "      <td>rec.autos</td>\n",
       "      <td>come silli hole hood tube hole think intak thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6465</th>\n",
       "      <td>rec.autos</td>\n",
       "      <td>explain sens drag coeffici mention magazin und...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6472</th>\n",
       "      <td>rec.autos</td>\n",
       "      <td>admit disgust featur volvo market look like vo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6478 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   topic                                       cleaned_text\n",
       "0     talk.religion.misc  slight differ note build state number roof man...\n",
       "2     talk.religion.misc  gordon bank quot add articl acsu buffalo chris...\n",
       "13    talk.religion.misc  oop right busi save frank post intend respond ...\n",
       "17    talk.religion.misc  word faith stronger faith provid miracl follow...\n",
       "18    talk.religion.misc  alexand destroy tyre peopl construct hous peop...\n",
       "...                  ...                                                ...\n",
       "6438           rec.autos  lincoln continent edsel ford design look abort...\n",
       "6441           rec.autos  answer question sort volkswagen robust version...\n",
       "6445           rec.autos  come silli hole hood tube hole think intak thi...\n",
       "6465           rec.autos  explain sens drag coeffici mention magazin und...\n",
       "6472           rec.autos  admit disgust featur volvo market look like vo...\n",
       "\n",
       "[6478 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df[['topic','cleaned_text']]\n",
    "y = df['target']\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "569180e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verilerin egitim ve test icin bolunmesi\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test,y_train,y_test = train_test_split(x,y,test_size=0.33,shuffle = True ,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58ca0298",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import utils\n",
    "\n",
    "one_hot_y_train = utils.to_categorical(y_train, num_classes)\n",
    "one_hot_y_test = utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9168baf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Ensar\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Ensar\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Ensar\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Ensar\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1126, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\Ensar\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Ensar\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 4), found shape=(None, 2)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(x_train, one_hot_y_train,\n\u001b[0;32m      2\u001b[0m                      epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m,\n\u001b[0;32m      3\u001b[0m                      verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m      4\u001b[0m                      validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[0;32m      5\u001b[0m                      batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file0knb53du.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Ensar\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Ensar\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Ensar\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Ensar\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1126, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\Ensar\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Ensar\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 4), found shape=(None, 2)\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, one_hot_y_train,\n",
    "                     epochs=40,\n",
    "                     verbose=-1,\n",
    "                     validation_split=0.2,\n",
    "                     batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44774421",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
